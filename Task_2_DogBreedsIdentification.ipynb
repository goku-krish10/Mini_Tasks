{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Complete all sub-tasks marked with ## TO DO! ## and submit the filled notebook on OLAT__ \\\n",
    "__Using a GPU is recommended here__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning ###\n",
    "Aim of this notebook is to implement the concept of transfer learning to train a bigger dataset. We try to compete on a well-known competiton on Kaggle known as Dog Breeds Identification. Read more about it here:\n",
    "\n",
    "https://www.kaggle.com/c/dog-breed-identification/overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model on the Dog breeds dataset using transfer learning and submit your results to Kaggle.\n",
    "Note: Below notebook gives some tips to run the code in pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda) # This implies Cuda is available for work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AlexNet import AlexNet\n",
    "from train_test import start_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "## TO DO! : Register on Kaggle With Your respective GroupName  (For example: WS20_VDL_GROUP_01)    ##\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "## TO DO! : Download the Dog-Breeds dataset in folder \"data\"                                      ##\n",
    "## from the Kaggle competition link mentioned above                                               ##\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "## TO DO! : Make your dataset to and dataloaders for the  test data \n",
    "####################################################################################################\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import transform as trf\n",
    "from pathlib import Path\n",
    "\n",
    "train_source_dir='Data_kaggle/train/'\n",
    "train_dest_dir='data/train/'\n",
    "test_source_dir='Data_kaggle/test/'\n",
    "test_dest_dir='data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8177\n",
      "2045\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([256, 3, 224, 224])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "####################################################################################################\n",
    "## TO DO! : Split train data into 20% validation set and make dataloaders for train and val split ##\n",
    "####################################################################################################\n",
    "\n",
    "#splitting the data into training and validation using the training data we have just taken out as we already have the test data\n",
    "\n",
    "# we are using the transform methods provided in the imports and the same automatically uses the augmentation internally\n",
    "train_data = datasets.ImageFolder(train_dest_dir,       \n",
    "                    transform=trf.transform_training())\n",
    "\n",
    "#test_data = datasets.ImageFolder()\n",
    "\n",
    "#splitting the dataset into training and validation set but I am not sure if this is the place to do it ...positioning wise after transform and before dataloaders\n",
    "\n",
    "train_size = int(0.8 * len(train_data))\n",
    "val_size = len(train_data) - train_size\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(train_data, [train_size, val_size])\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(validation_dataset))\n",
    "\n",
    "\n",
    "# train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=256,  #The batch size is the same as what we have in the config.py\n",
    "#                                shuffle = True)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=256,  #The batch size is the same as what we have in the config.py\n",
    "                               shuffle = True)\n",
    "\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=256,  #The batch size is the same as what we have in the config.py\n",
    "                               shuffle = True)\n",
    "\n",
    "# print(train_data[0])\n",
    "dataiter = iter(train_dataloader)\n",
    "data,labels = dataiter.next()\n",
    "\n",
    "print(type(data))\n",
    "print(data.shape)\n",
    "print(labels.shape)\n",
    "#data.shape gives the output of the form [batch_size,colour,height,width]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HINT: \n",
    "# One can make their own custom dataset and dataloaders using the CSV file or\n",
    "# Convert the Dog-breed training dataset into Imagenet Format, where all images of one class are in a\n",
    "# folder named with class as in the below given format. Standard Pytorch Datasets and Dataloaders can then be applied\n",
    "# over them\n",
    "# Root\n",
    "# |\n",
    "# |---Class1 ___Img1.png\n",
    "# |          ___Img2.png\n",
    "# |\n",
    "# |---Class2 ___Img3.png\n",
    "# |          ___Img4.png\n",
    "# |....\n",
    "# |....\n",
    "\n",
    "#Custom Dataset\n",
    "#loading and sorting the labels based on the id column \n",
    "# The data has been sorted to get the labels in sync with the ids specified in the labels,csv\n",
    "\n",
    "labels = pd.read_csv('Data_kaggle/labels.csv')\n",
    "labels.sort_values(by=['id']) \n",
    "\n",
    "\n",
    "# Arranging the data in an appropriate dataset of classes\n",
    "unique_labels=list(labels.breed.unique())\n",
    "count=0\n",
    "# getting the list of ids and copy pasting them in appropriate folders\n",
    "for x in unique_labels:\n",
    "#      print(\"===========================================================\\n\")\n",
    "    id_list_by_class=list(labels.query('breed==@x')['id'])\n",
    "    count+=1\n",
    "    class_path=os.path.join(train_dest_dir,str(x)) \n",
    "    os.makedirs(class_path,exist_ok=True)\n",
    "    for img in id_list_by_class:\n",
    "        src_file=os.path.join(train_source_dir,img+'.jpg')\n",
    "        shutil.copy2(src_file, class_path) \n",
    "print(\"class folders along with the appropriate images done successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Train famous Alexnet model on Dog breeds dataset. It is not easy to train the alexnet model from \n",
    "scratch on the Dog breeds data itself. Curious minds can try for once to train Alexnet from scratch. We adopt Transfer Learning here. We \n",
    "obtain a pretrained Alexnet model trained on Imagenet and apply transfer learning to it to get better results.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Sequential(\n",
      "      (0): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "      (3): Linear(in_features=1000, out_features=120, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> Training Epoch #1, LR=0.0010\n",
      "| Epoch [  1/  5] \t\tLoss: 3.4090 Acc@1: 15.690%\n",
      "\n",
      "| Validation Epoch #1\t\t\tLoss: 3.2679 Acc@1: 26.36%\n",
      "* Test results : Acc@1 = 26.36%\n",
      "| Elapsed time : 0:01:04\n",
      "\n",
      "=> Training Epoch #2, LR=0.0010\n",
      "| Epoch [  2/  5] \t\tLoss: 3.0795 Acc@1: 24.985%\n",
      "\n",
      "| Validation Epoch #2\t\t\tLoss: 3.0357 Acc@1: 28.26%\n",
      "* Test results : Acc@1 = 28.26%\n",
      "| Elapsed time : 0:02:00\n",
      "\n",
      "=> Training Epoch #3, LR=0.0010\n",
      "| Epoch [  3/  5] \t\tLoss: 3.1342 Acc@1: 27.015%\n",
      "\n",
      "| Validation Epoch #3\t\t\tLoss: 3.0723 Acc@1: 27.63%\n",
      "* Test results : Acc@1 = 28.26%\n",
      "| Elapsed time : 0:02:57\n",
      "\n",
      "=> Training Epoch #4, LR=0.0010\n",
      "| Epoch [  4/  5] \t\tLoss: 2.7383 Acc@1: 29.179%\n",
      "\n",
      "| Validation Epoch #4\t\t\tLoss: 2.7522 Acc@1: 30.17%\n",
      "* Test results : Acc@1 = 30.17%\n",
      "| Elapsed time : 0:03:53\n",
      "\n",
      "=> Training Epoch #5, LR=0.0010\n",
      "| Epoch [  5/  5] \t\tLoss: 2.7591 Acc@1: 30.207%\n",
      "\n",
      "| Validation Epoch #5\t\t\tLoss: 2.7276 Acc@1: 30.42%\n",
      "* Test results : Acc@1 = 30.42%\n",
      "| Elapsed time : 0:04:50\n"
     ]
    }
   ],
   "source": [
    "####################################################################################################\n",
    "## TO DO! :  Freeze the weigths of the pretrained alexnet model and change the last classification layer\n",
    "##from 1000 classes of Imagenet to 120 classes of Dog Breeds, only classification layer should be \n",
    "## unfreezed and trainable                                                                        ##\n",
    "####################################################################################################\n",
    "from torch import optim #importing for Adam Optimizer as defined in the config file \n",
    "\n",
    "import torchvision.models as models\n",
    "pretrained_alexnet = models.alexnet(pretrained=True)\n",
    "\n",
    "#printing the model\n",
    "# print(pretrained_alexnet)\n",
    "\n",
    "\n",
    "#freezing the alexnet learned parameters except the last classification layer \n",
    "\n",
    "for param in pretrained_alexnet.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "#adding the final layer for classification\n",
    "\n",
    "print(\"==========================================================\")\n",
    "pretrained_alexnet.classifier[6]= nn.Sequential(\n",
    "                                  nn.Linear(4096, 1000), \n",
    "                                  nn.ReLU(), \n",
    "                                  nn.Dropout(0.2),\n",
    "                                  nn.Linear(1000, 120))\n",
    "\n",
    "#pretrained_alexnet.classifier[6] = nn.Linear(4096,120)\n",
    "\n",
    "\n",
    "print(pretrained_alexnet)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "pretrained_alexnet = pretrained_alexnet.to(device)  #moving thr alexnet to gpu \n",
    "\n",
    "# # for param in pretrained_alexnet.classification.parameters():\n",
    "# #     param.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(pretrained_alexnet.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "# print(pretrained_alexnet)\n",
    "# # Below function will directly train your network with the given parameters to 5 epochs\n",
    "# # You are also free to use function learned in task 1 to train your model here \n",
    "# # train_loss, test_loss = start_train_test(pretrained_alexnet, trainloader, testloader, criterion)\n",
    "\n",
    "#learning rate was changed to 0.001 to achieve better accuracy\n",
    "train_loss, test_loss = start_train_test(pretrained_alexnet, train_dataloader, validation_dataloader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform import transform_testing\n",
    "import PIL.Image\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10357, 120)\n"
     ]
    }
   ],
   "source": [
    "### Not So optimal Code: This can take upto 2 minutes to run: You are free to make an optimal version :) ###\n",
    "# It iterates over all test images to compute the softmax probablities from the last layer of the network\n",
    "augment_image = transform_testing()\n",
    "test_data_root = 'Data_kaggle/test/' \n",
    "test_image_list = os.listdir(test_data_root) # list of test files \n",
    "result = []\n",
    "for img_name in test_image_list:\n",
    "    img = PIL.Image.open(test_data_root + img_name)\n",
    "    img_tensor = augment_image(img)\n",
    "    with torch.no_grad():\n",
    "        #output = pretrained_resnet(img_tensor.unsqueeze_(0).cuda())\n",
    "        output = pretrained_alexnet(img_tensor.unsqueeze_(0).cuda())\n",
    "        probs = F.softmax(output, dim=1)\n",
    "    result.append(probs.cpu().numpy())\n",
    "all_predictions = np.concatenate(result)\n",
    "print(all_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_predictions)\n",
    "file_list = os.listdir('data/train') # list of classes to be provided here\n",
    "df.columns = sorted(file_list)\n",
    "\n",
    "# insert clean ids - without folder prefix and .jpg suffix - of images as first column\n",
    "test_data_root = 'Data_kaggle/test/' # list of all test files here\n",
    "test_image_list = os.listdir(test_data_root)\n",
    "df.insert(0, \"id\", [e[:-4] for e in test_image_list])\n",
    "df.to_csv(f\"sub_1_alexnet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO!: ###\n",
    "Submit the created CSV file to Kaggle, with a score(cross entropy loss) not more than __2.0__\\\n",
    "Take a snapshot of your evaluation score and  include the image here ...\n",
    "For example :\n",
    "![title](Kaggle_submission.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
